{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Tutorial 2: REST API Integration Patterns\n",
    "\n",
    "**Level:** Intermediate  \n",
    "**Time:** 20-25 minutes  \n",
    "**Prerequisites:** Basic tutorials\n",
    "\n",
    "## Overview\n",
    "\n",
    "Professional REST API integration:\n",
    "- Authentication best practices\n",
    "- Token refresh strategies\n",
    "- Rate limiting and retry logic\n",
    "- Error handling patterns\n",
    "- Batch operations\n",
    "- API client wrapper\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "BASE_URL = \"http://localhost:8000/api/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Professional API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroGraphClient:\n",
    "    \"\"\"Production-ready API client with auto-refresh and retry logic.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str, username: str, password: str):\n",
    "        self.base_url = base_url\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.access_token: Optional[str] = None\n",
    "        self.refresh_token: Optional[str] = None\n",
    "        self.token_expires_at: Optional[datetime] = None\n",
    "        \n",
    "    def login(self):\n",
    "        \"\"\"Initial authentication.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/auth/login\",\n",
    "            json={\"username\": self.username, \"password\": self.password}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        self.access_token = data[\"access_token\"]\n",
    "        self.refresh_token = data[\"refresh_token\"]\n",
    "        self.token_expires_at = datetime.now() + timedelta(seconds=data[\"expires_in\"])\n",
    "        \n",
    "        print(f\"✓ Logged in as {data['user']['username']}\")\n",
    "    \n",
    "    def refresh_access_token(self):\n",
    "        \"\"\"Refresh expired access token.\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/auth/refresh\",\n",
    "            json={\"refresh_token\": self.refresh_token}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        self.access_token = data[\"access_token\"]\n",
    "        self.refresh_token = data[\"refresh_token\"]\n",
    "        self.token_expires_at = datetime.now() + timedelta(seconds=data[\"expires_in\"])\n",
    "        \n",
    "        print(\"✓ Token refreshed\")\n",
    "    \n",
    "    def ensure_valid_token(self):\n",
    "        \"\"\"Ensure access token is valid, refresh if needed.\"\"\"\n",
    "        if not self.access_token:\n",
    "            self.login()\n",
    "        elif datetime.now() >= self.token_expires_at - timedelta(seconds=30):\n",
    "            self.refresh_access_token()\n",
    "    \n",
    "    def request(self, method: str, endpoint: str, **kwargs) -> requests.Response:\n",
    "        \"\"\"Make authenticated request with auto-retry.\"\"\"\n",
    "        self.ensure_valid_token()\n",
    "        \n",
    "        headers = kwargs.get(\"headers\", {})\n",
    "        headers[\"Authorization\"] = f\"Bearer {self.access_token}\"\n",
    "        kwargs[\"headers\"] = headers\n",
    "        \n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        \n",
    "        # Retry logic\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.request(method, url, **kwargs)\n",
    "                \n",
    "                # Retry on 401 (token might have expired mid-request)\n",
    "                if response.status_code == 401 and attempt < max_retries - 1:\n",
    "                    self.refresh_access_token()\n",
    "                    headers[\"Authorization\"] = f\"Bearer {self.access_token}\"\n",
    "                    continue\n",
    "                \n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "    \n",
    "    # Convenience methods\n",
    "    def get(self, endpoint: str, **kwargs):\n",
    "        return self.request(\"GET\", endpoint, **kwargs)\n",
    "    \n",
    "    def post(self, endpoint: str, **kwargs):\n",
    "        return self.request(\"POST\", endpoint, **kwargs)\n",
    "    \n",
    "    def put(self, endpoint: str, **kwargs):\n",
    "        return self.request(\"PUT\", endpoint, **kwargs)\n",
    "    \n",
    "    def delete(self, endpoint: str, **kwargs):\n",
    "        return self.request(\"DELETE\", endpoint, **kwargs)\n",
    "\n",
    "# Create client\n",
    "client = NeuroGraphClient(BASE_URL, \"admin\", \"admin\")\n",
    "client.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Using the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token\n",
    "response = client.post(\"/tokens\", json={\n",
    "    \"position\": [1.0]*8,\n",
    "    \"radius\": 1.0,\n",
    "    \"weight\": 1.0\n",
    "})\n",
    "token = response.json()\n",
    "print(f\"✓ Created token {token['token_id']}\")\n",
    "\n",
    "# Get token\n",
    "response = client.get(f\"/tokens/{token['token_id']}\")\n",
    "print(f\"✓ Retrieved: {response.json()}\")\n",
    "\n",
    "# Delete token\n",
    "client.delete(f\"/tokens/{token['token_id']}\")\n",
    "print(\"✓ Deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Rate Limiting Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from time import time\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"Token bucket rate limiter.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_requests: int, window_seconds: int):\n",
    "        self.max_requests = max_requests\n",
    "        self.window = window_seconds\n",
    "        self.requests = deque()\n",
    "    \n",
    "    def acquire(self):\n",
    "        \"\"\"Wait if rate limit exceeded.\"\"\"\n",
    "        now = time()\n",
    "        \n",
    "        # Remove old requests\n",
    "        while self.requests and self.requests[0] < now - self.window:\n",
    "            self.requests.popleft()\n",
    "        \n",
    "        # Check limit\n",
    "        if len(self.requests) >= self.max_requests:\n",
    "            sleep_time = self.window - (now - self.requests[0])\n",
    "            print(f\"Rate limit: sleeping {sleep_time:.2f}s\")\n",
    "            time.sleep(sleep_time)\n",
    "            self.requests.popleft()\n",
    "        \n",
    "        self.requests.append(now)\n",
    "\n",
    "# Demo: 5 requests per 10 seconds\n",
    "limiter = RateLimiter(max_requests=5, window_seconds=10)\n",
    "\n",
    "for i in range(7):\n",
    "    limiter.acquire()\n",
    "    print(f\"Request {i+1} at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "print(\"✓ Rate limiting working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Batch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_create_tokens(client, count: int, batch_size: int = 10):\n",
    "    \"\"\"Create tokens in batches with progress.\"\"\"\n",
    "    created = []\n",
    "    \n",
    "    for i in range(0, count, batch_size):\n",
    "        batch = []\n",
    "        \n",
    "        for j in range(min(batch_size, count - i)):\n",
    "            response = client.post(\"/tokens\", json={\n",
    "                \"position\": [float(i+j)]*8,\n",
    "                \"radius\": 1.0,\n",
    "                \"weight\": 1.0\n",
    "            })\n",
    "            batch.append(response.json())\n",
    "        \n",
    "        created.extend(batch)\n",
    "        print(f\"✓ Created batch {i//batch_size + 1}: {len(batch)} tokens\")\n",
    "    \n",
    "    return created\n",
    "\n",
    "# Create 25 tokens in batches of 10\n",
    "tokens = batch_create_tokens(client, count=25, batch_size=10)\n",
    "print(f\"\\n✓ Total created: {len(tokens)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Error Handling Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    NETWORK = \"network\"\n",
    "    AUTH = \"auth\"\n",
    "    VALIDATION = \"validation\"\n",
    "    NOT_FOUND = \"not_found\"\n",
    "    SERVER = \"server\"\n",
    "\n",
    "def handle_api_error(error: requests.exceptions.RequestException) -> ErrorType:\n",
    "    \"\"\"Classify and handle API errors.\"\"\"\n",
    "    if isinstance(error, requests.exceptions.ConnectionError):\n",
    "        print(\"❌ Network error: Server unreachable\")\n",
    "        return ErrorType.NETWORK\n",
    "    \n",
    "    if isinstance(error, requests.exceptions.HTTPError):\n",
    "        status = error.response.status_code\n",
    "        \n",
    "        if status == 401:\n",
    "            print(\"❌ Authentication failed\")\n",
    "            return ErrorType.AUTH\n",
    "        elif status == 404:\n",
    "            print(\"❌ Resource not found\")\n",
    "            return ErrorType.NOT_FOUND\n",
    "        elif status == 422:\n",
    "            print(f\"❌ Validation error: {error.response.json()}\")\n",
    "            return ErrorType.VALIDATION\n",
    "        elif status >= 500:\n",
    "            print(\"❌ Server error\")\n",
    "            return ErrorType.SERVER\n",
    "    \n",
    "    print(f\"❌ Unknown error: {error}\")\n",
    "    return ErrorType.NETWORK\n",
    "\n",
    "# Demo error handling\n",
    "try:\n",
    "    client.get(\"/tokens/999999\")  # Non-existent token\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    error_type = handle_api_error(e)\n",
    "    print(f\"Classified as: {error_type.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all tokens\n",
    "response = client.get(\"/tokens\")\n",
    "all_tokens = response.json()\n",
    "\n",
    "for token in all_tokens:\n",
    "    client.delete(f\"/tokens/{token['token_id']}\")\n",
    "\n",
    "print(f\"✓ Cleaned up {len(all_tokens)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **API Client** - Production-ready with auto-refresh  \n",
    "✅ **Token management** - Automatic refresh before expiry  \n",
    "✅ **Retry logic** - Exponential backoff on failures  \n",
    "✅ **Rate limiting** - Token bucket algorithm  \n",
    "✅ **Batch operations** - Efficient bulk processing  \n",
    "✅ **Error handling** - Classify and recover from errors  \n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Always use token refresh** before expiry (30s buffer)\n",
    "2. **Implement retry logic** with exponential backoff\n",
    "3. **Respect rate limits** to avoid 429 errors\n",
    "4. **Batch operations** reduce network overhead\n",
    "5. **Error classification** enables smart recovery\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Advanced Tutorial 1 - Performance Optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
